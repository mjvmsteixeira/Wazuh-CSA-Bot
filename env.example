# Wazuh API Configuration
WAZUH_API_URL=https://127.0.0.1:55000
WAZUH_USER=wazuh
WAZUH_PASSWORD=your_wazuh_password_here
WAZUH_VERIFY_SSL=false

# AI Configuration Mode
# Options: "local", "external", "mixed"
# - local: Only vLLM (internal GPU-based model) - vLLM container will start
# - external: Only OpenAI/Cloud APIs - vLLM container will NOT start
# - mixed: Both available, user can choose - vLLM container will start
AI_MODE=mixed

# Local LLM (vLLM Docker) - Only used if AI_MODE is "local" or "mixed"
VLLM_API_URL=http://vllm:8000/v1
VLLM_MODEL=meta-llama/Meta-Llama-3-8B-Instruct

# External LLM (OpenAI) - Only used if AI_MODE is "external" or "mixed"
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_BASE_URL=https://api.openai.com/v1

# Application Settings
APP_ENV=development
APP_PORT=8000
LOG_LEVEL=INFO
SECRET_KEY=your_secret_key_here

# Database (optional - for history)
DATABASE_URL=sqlite:///./sca_history.db

# Redis Cache (optional)
REDIS_URL=redis://redis:6379/0
